{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JS03-Keras callbacks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/peaelle42/DNN_jump_start/blob/master/JS03_Keras_callbacks.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "X6EOUvZ29KWO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing for GPU\n",
        "To Test if you have GPU set up\n",
        "\n",
        "Run the Cell below\n",
        "\n",
        "if no GPU is found press Runtime (in the menu at the top) and choose \"Change Runtime Type\" to GPU"
      ]
    },
    {
      "metadata": {
        "id": "2gdXqj0o9Ip4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d8e6a39-13db-40c3-ae61-d0bab3411b9a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kWef1NvKGczH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras Callbacks\n",
        "\n",
        "This is to show implementations of Keras Callbacks and how to use them\n",
        "\n",
        "- Basic History and plotting  \n",
        "- Model checkpoints  \n",
        "- Early Stopping  \n",
        "- Learning Rate Scheduler  \n",
        "- ReduceLROnPlateau  \n",
        "- LambdaCallback\n",
        "- Custom Callback  "
      ]
    },
    {
      "metadata": {
        "id": "-_40C_H5GczI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set up a model"
      ]
    },
    {
      "metadata": {
        "id": "T7QANXfPGczJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, Callback, ReduceLROnPlateau, LearningRateScheduler, EarlyStopping, TensorBoard\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_yjZMHPMGczP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7212f06d-390e-4cd9-9406-f45513459de6"
      },
      "cell_type": "code",
      "source": [
        "print(keras.__version__)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.6\n",
            "1.9.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jbr6rIgLGczT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "c88cc0df-b598-4197-cfd5-8d7953b8290b"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sL8Fc_CqGczW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nNkc7iZcGczZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "7e4ee805-0cb0-4528-fcb7-0905e8bff148"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,),name='Dense1'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu',name='Dense2'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Dense1 (Dense)               (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "Dense2 (Dense)               (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CP39yLliGczc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lF0gOJWNGcze",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic History and ploting"
      ]
    },
    {
      "metadata": {
        "id": "CtNTvZSGGczf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a99bc41f-e7af-48c0-8848-0c8196bf0a8f"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=5,\n",
        "                    verbose=2,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            " - 4s - loss: 0.2464 - acc: 0.9237 - val_loss: 0.1060 - val_acc: 0.9673\n",
            "Epoch 2/5\n",
            " - 3s - loss: 0.1039 - acc: 0.9679 - val_loss: 0.0938 - val_acc: 0.9715\n",
            "Epoch 3/5\n",
            " - 3s - loss: 0.0754 - acc: 0.9767 - val_loss: 0.0794 - val_acc: 0.9760\n",
            "Epoch 4/5\n",
            " - 3s - loss: 0.0608 - acc: 0.9819 - val_loss: 0.0691 - val_acc: 0.9797\n",
            "Epoch 5/5\n",
            " - 3s - loss: 0.0510 - acc: 0.9850 - val_loss: 0.0718 - val_acc: 0.9807\n",
            "Test loss: 0.07180944553018781\n",
            "Test accuracy: 0.9807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IrYYDxmpGczi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_train(hist):\n",
        "    h = hist.history\n",
        "    if 'acc' in h:\n",
        "        meas='acc'\n",
        "        loc='lower right'\n",
        "    else:\n",
        "        meas='loss'\n",
        "        loc='upper right'\n",
        "    plt.plot(hist.history[meas])\n",
        "    plt.plot(hist.history['val_'+meas])\n",
        "    plt.title('model '+meas)\n",
        "    plt.ylabel(meas)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc=loc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7DQW_6yAGczk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "1def4e1b-5873-4102-e722-73238b41de53"
      },
      "cell_type": "code",
      "source": [
        "plot_train(history)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEVCAYAAAAPRfkLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f38d6e6fba8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Fhzx-BqFGczl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Checkpoints\n",
        "\n",
        "args \n",
        "- filepath - str  can use formating to put epoch number etc {epoc}\n",
        "- monitor - qunatity to monitor  \n",
        "- verbose - 0 or 1  \n",
        "- save_best_only - only save if better than before  \n",
        "- mode - use 'auto'  \n",
        "- save_weights_only - if false then will save whole model\n",
        "- period - the interval between epochs  "
      ]
    },
    {
      "metadata": {
        "id": "XLfiKxxK93vh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "vb0THk4Q94eu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e6558e4-1522-4fb7-8ca7-c1dceb7d235a"
      },
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints\n",
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cats-dogs.hdf5\tcheckpoints  data  datalab  gdrive.py  __pycache__  sutils.py\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-3eFE4-VGczm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('./checkpoints/weights_{epoch:02d}_{val_acc:.2f}.hdf5', verbose=1, save_best_only=True, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "So5IqbuTGczo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "332af695-b8f5-4231-9817-72c0e7f52cb2"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=0,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[checkpoint])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.08551, saving model to ./checkpoints/weights_01_0.98.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.08551 to 0.07574, saving model to ./checkpoints/weights_02_0.98.hdf5\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.07574\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.07574\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.07574\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.07574\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.07574\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.07574\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.07574\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.07574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38ce693e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "txXENk5n-QYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a56e449c-3ca9-4e7f-a0bc-bd60191a2c4a"
      },
      "cell_type": "code",
      "source": [
        "!mkdir logs\n",
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cats-dogs.hdf5\tdata\t gdrive.py  __pycache__\r\n",
            "checkpoints\tdatalab  logs\t    sutils.py\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ewM8SlhfGcz6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Early Stopping - stop training when a monitored quanity has stopped improving\n",
        "args\n",
        "- monitor : what to monitor 'val_loss', 'acc'\n",
        "- min_delta :minimum change to qualify as improvement\n",
        "- patience : number of epocs with no improvement before you stop\n",
        "- verbose : verbosity mode\n",
        "- mode : 'auto' , can be 'min' or 'max' determines direction of improvement. Auto = based on monitor"
      ]
    },
    {
      "metadata": {
        "id": "_H9Q2a5yGcz7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=0,verbose=0,mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3m6dyc74Gcz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "a2f93fe7-6ad7-4762-cb9f-42d9d5172120"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0212 - acc: 0.9944 - val_loss: 0.1050 - val_acc: 0.9841\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0204 - acc: 0.9945 - val_loss: 0.0997 - val_acc: 0.9833\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0204 - acc: 0.9948 - val_loss: 0.1194 - val_acc: 0.9818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38ce630320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "n_nNbM2uGcz_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "above stopped after 3 epochs instead of 10 as validation loss didn't get better"
      ]
    },
    {
      "metadata": {
        "id": "ophrgrNSGcz_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Learning Rate Scheduler\n",
        "arg\n",
        "- schedule - this will be function that takes epoch number(int) and returns new Learning Rate (float) "
      ]
    },
    {
      "metadata": {
        "id": "VA3t30AJGcz_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### LearningRate = InitialLearningRate * DropRate^floor(Epoch / EpochDrop)"
      ]
    },
    {
      "metadata": {
        "id": "4QvA3kSwGc0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# learning rate schedule for dropping every 10 epochs\n",
        "def LRDropping(epoch_hi_there):\n",
        "    initial_lrate = 0.001\n",
        "    drop = 0.9\n",
        "    epochs_drop = 3.0\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch_hi_there)/epochs_drop))\n",
        "    print(lrate)\n",
        "    return lrate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZZ8gfVeGc0B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9f8c46af-9da5-4f8d-af7d-abd2b507c29c"
      },
      "cell_type": "code",
      "source": [
        "LRDropping(56)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0001350851717672993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001350851717672993"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "xGl6BTmSGc0D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LRDrop = LearningRateScheduler(LRDropping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6HKkjUBASXnG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def LRS(function):\n",
        "#   epoch = ask_keras_epocj\n",
        "#   function(epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6DZuRxryGc0E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.set_value(model.optimizer.lr,0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YnphZGZXGc0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "152cf187-72d1-41a4-cf15-e33f3ea8838e"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[LRDrop])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "0.001\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0147 - acc: 0.9965 - val_loss: 0.1106 - val_acc: 0.9847\n",
            "Epoch 2/10\n",
            "0.001\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0159 - acc: 0.9960 - val_loss: 0.1150 - val_acc: 0.9847\n",
            "Epoch 3/10\n",
            "0.0009000000000000001\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0126 - acc: 0.9970 - val_loss: 0.1263 - val_acc: 0.9842\n",
            "Epoch 4/10\n",
            "0.0009000000000000001\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0124 - acc: 0.9970 - val_loss: 0.1242 - val_acc: 0.9840\n",
            "Epoch 5/10\n",
            "0.0009000000000000001\n",
            " 6144/60000 [==>...........................] - ETA: 3s - loss: 0.0127 - acc: 0.9979"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.1377 - val_acc: 0.9807\n",
            "Epoch 6/10\n",
            "0.0008100000000000001\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.1259 - val_acc: 0.9844\n",
            "Epoch 7/10\n",
            "0.0008100000000000001\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0098 - acc: 0.9976 - val_loss: 0.1284 - val_acc: 0.9838\n",
            "Epoch 8/10\n",
            "0.0008100000000000001\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0109 - acc: 0.9977 - val_loss: 0.1400 - val_acc: 0.9835\n",
            "Epoch 9/10\n",
            "0.0007290000000000002\n",
            "25088/60000 [===========>..................] - ETA: 1s - loss: 0.0061 - acc: 0.9985"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.0072 - acc: 0.9984 - val_loss: 0.1251 - val_acc: 0.9855\n",
            "Epoch 10/10\n",
            "0.0007290000000000002\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.1318 - val_acc: 0.9842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38cd6eeef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "FFvcsbdBGc0H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d44473b3-fca0-4029-cc02-17d417f892d9"
      },
      "cell_type": "code",
      "source": [
        "#print out the learning rate\n",
        "print(K.eval(model.optimizer.lr))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.000729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0LgZLvEWGc0J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ReduceLROnPlateau\n",
        "args\n",
        "- monitor : quality to be monitored eg. 'val_loss' , 'val_acc'\n",
        "- factor : the factor by which the current LR be multiplied  \n",
        "- patience : number of epochs with no improvement  \n",
        "- verbose : 1 = update messages 0 nothing\n",
        "- mode : 'auto'  eg. is improvment up or down 'min' 'max'\n",
        "- epsilon : threshold for measuring the new optimum, to only focus on significant changes  \n",
        "- cooldown :number of epochs to wait before any new changes\n",
        "- min_lr: the lowest lr allowed "
      ]
    },
    {
      "metadata": {
        "id": "hOZ6WgCMGc0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reduce_LR = ReduceLROnPlateau(monitor='val_loss',factor = 0.9, patience=3,cooldown=2, min_lr = 0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6TIEdjMCGc0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "224f4e87-9208-4390-a601-decf41fd4703"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[reduce_LR])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0085 - acc: 0.9980 - val_loss: 0.1292 - val_acc: 0.9848\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0072 - acc: 0.9983 - val_loss: 0.1311 - val_acc: 0.9853\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0074 - acc: 0.9984 - val_loss: 0.1456 - val_acc: 0.9843\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0068 - acc: 0.9984 - val_loss: 0.1386 - val_acc: 0.9834\n",
            "Epoch 5/10\n",
            "14464/60000 [======>.......................] - ETA: 2s - loss: 0.0073 - acc: 0.9987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0065 - acc: 0.9986 - val_loss: 0.1299 - val_acc: 0.9848\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0057 - acc: 0.9986 - val_loss: 0.1385 - val_acc: 0.9850\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0067 - acc: 0.9987 - val_loss: 0.1342 - val_acc: 0.9839\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.1324 - val_acc: 0.9849\n",
            "Epoch 9/10\n",
            "41472/60000 [===================>..........] - ETA: 1s - loss: 0.0049 - acc: 0.9989"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0052 - acc: 0.9989 - val_loss: 0.1417 - val_acc: 0.9841\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.0040 - acc: 0.9992 - val_loss: 0.1389 - val_acc: 0.9848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38cda8dfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "60nxRcHyGc0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56407568-1582-499f-c578-2a0e317bce3a"
      },
      "cell_type": "code",
      "source": [
        "#print out the learning rate\n",
        "print(K.eval(model.optimizer.lr))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00059049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u00EDKerGc0Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LambdaCallback a way to call anon functions in the callback\n",
        "args\n",
        "- on_epoch_being - called at begin of epoch -takes epoch,logs\n",
        "- on_epoch_end - called at end of epoch -takes epoch,logs\n",
        "- on_batch_begin _ called a begin of a batch -takes batch,logs\n",
        "- on_batch_end :-takes epoch,logs\n",
        "- on_train_begin - -takes logs\n",
        "- on_train_end - -takes logs"
      ]
    },
    {
      "metadata": {
        "id": "etf7iWQLGc0R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_print = LambdaCallback(on_epoch_begin=lambda epoch,logs: print(\"lr:\",K.eval(model.optimizer.lr)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zZZ8S6hDGc0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "ef6c1d8b-1801-4d82-c45f-3d872162cfcd"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[lr_print,LRDrop])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "lr: 0.00059049\n",
            "0.001\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.0095 - acc: 0.9980 - val_loss: 0.1407 - val_acc: 0.9833\n",
            "Epoch 2/10\n",
            "lr: 0.001\n",
            "0.001\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.1436 - val_acc: 0.9849\n",
            "Epoch 3/10\n",
            "lr: 0.001\n",
            "0.0009000000000000001\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0113 - acc: 0.9977 - val_loss: 0.1314 - val_acc: 0.9848\n",
            "Epoch 4/10\n",
            "lr: 0.0009\n",
            "0.0009000000000000001\n",
            "57472/60000 [===========================>..] - ETA: 0s - loss: 0.0107 - acc: 0.9977"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0106 - acc: 0.9977 - val_loss: 0.1292 - val_acc: 0.9856\n",
            "Epoch 5/10\n",
            "lr: 0.0009\n",
            "0.0009000000000000001\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0086 - acc: 0.9982 - val_loss: 0.1409 - val_acc: 0.9845\n",
            "Epoch 6/10\n",
            "lr: 0.0009\n",
            "0.0008100000000000001\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0079 - acc: 0.9984 - val_loss: 0.1320 - val_acc: 0.9848\n",
            "Epoch 7/10\n",
            "lr: 0.00081\n",
            "0.0008100000000000001\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0075 - acc: 0.9985 - val_loss: 0.1453 - val_acc: 0.9848\n",
            "Epoch 8/10\n",
            "lr: 0.00081\n",
            "0.0008100000000000001\n",
            "24448/60000 [===========>..................] - ETA: 2s - loss: 0.0084 - acc: 0.9982"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0081 - acc: 0.9982 - val_loss: 0.1464 - val_acc: 0.9828\n",
            "Epoch 9/10\n",
            "lr: 0.00081\n",
            "0.0007290000000000002\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0078 - acc: 0.9984 - val_loss: 0.1352 - val_acc: 0.9841\n",
            "Epoch 10/10\n",
            "lr: 0.000729\n",
            "0.0007290000000000002\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0067 - acc: 0.9986 - val_loss: 0.1381 - val_acc: 0.9850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38ce610e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "vA6oIdcfGc0W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}